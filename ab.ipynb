{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('sales_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2564</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2565</td>\n",
       "      <td>549.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>239.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2573</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>07.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>09.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2593</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2609</td>\n",
       "      <td>1699.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2548</td>\n",
       "      <td>1708.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2611</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2546</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2515</td>\n",
       "      <td>1649.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935819</th>\n",
       "      <td>16.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7789</td>\n",
       "      <td>1799.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935820</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7790</td>\n",
       "      <td>799.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935821</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7791</td>\n",
       "      <td>899.50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935822</th>\n",
       "      <td>17.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7632</td>\n",
       "      <td>2310.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935823</th>\n",
       "      <td>26.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7487</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935824</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7029</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935825</th>\n",
       "      <td>23.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935826</th>\n",
       "      <td>04.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935827</th>\n",
       "      <td>18.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935828</th>\n",
       "      <td>21.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>479.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935829</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935830</th>\n",
       "      <td>11.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7286</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935831</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7187</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935832</th>\n",
       "      <td>26.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7484</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935833</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935834</th>\n",
       "      <td>29.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7235</td>\n",
       "      <td>298.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935835</th>\n",
       "      <td>18.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935836</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935837</th>\n",
       "      <td>24.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7328</td>\n",
       "      <td>249.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935838</th>\n",
       "      <td>17.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7338</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935839</th>\n",
       "      <td>24.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7315</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935840</th>\n",
       "      <td>31.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935841</th>\n",
       "      <td>11.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7393</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935842</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7384</td>\n",
       "      <td>749.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935843</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  \\\n",
       "0        02.01.2013               0       59    22154      999.00   \n",
       "1        03.01.2013               0       25     2552      899.00   \n",
       "2        05.01.2013               0       25     2552      899.00   \n",
       "3        06.01.2013               0       25     2554     1709.05   \n",
       "4        15.01.2013               0       25     2555     1099.00   \n",
       "5        10.01.2013               0       25     2564      349.00   \n",
       "6        02.01.2013               0       25     2565      549.00   \n",
       "7        04.01.2013               0       25     2572      239.00   \n",
       "8        11.01.2013               0       25     2572      299.00   \n",
       "9        03.01.2013               0       25     2573      299.00   \n",
       "10       03.01.2013               0       25     2574      399.00   \n",
       "11       05.01.2013               0       25     2574      399.00   \n",
       "12       07.01.2013               0       25     2574      399.00   \n",
       "13       08.01.2013               0       25     2574      399.00   \n",
       "14       10.01.2013               0       25     2574      399.00   \n",
       "15       11.01.2013               0       25     2574      399.00   \n",
       "16       13.01.2013               0       25     2574      399.00   \n",
       "17       16.01.2013               0       25     2574      399.00   \n",
       "18       26.01.2013               0       25     2574      399.00   \n",
       "19       27.01.2013               0       25     2574      399.00   \n",
       "20       09.01.2013               0       25     2593      279.00   \n",
       "21       16.01.2013               0       25     2604      299.00   \n",
       "22       27.01.2013               0       25     2604      299.00   \n",
       "23       27.01.2013               0       25     2607      279.00   \n",
       "24       29.01.2013               0       25     2607      279.00   \n",
       "25       27.01.2013               0       25     2609     1699.00   \n",
       "26       06.01.2013               0       25     2548     1708.95   \n",
       "27       26.01.2013               0       25     2611      299.00   \n",
       "28       02.01.2013               0       25     2546      299.00   \n",
       "29       06.01.2013               0       25     2515     1649.00   \n",
       "...             ...             ...      ...      ...         ...   \n",
       "2935819  16.10.2015              33       25     7789     1799.00   \n",
       "2935820  22.10.2015              33       25     7790      799.00   \n",
       "2935821  22.10.2015              33       25     7791      899.50   \n",
       "2935822  17.10.2015              33       25     7632     2310.00   \n",
       "2935823  26.10.2015              33       25     7487      299.00   \n",
       "2935824  14.10.2015              33       25     7029      999.00   \n",
       "2935825  23.10.2015              33       25     7460      299.00   \n",
       "2935826  04.10.2015              33       25     7233      599.00   \n",
       "2935827  18.10.2015              33       25     7308      349.00   \n",
       "2935828  21.10.2015              33       25     7233      479.00   \n",
       "2935829  03.10.2015              33       25     7233      599.00   \n",
       "2935830  11.10.2015              33       25     7286      299.00   \n",
       "2935831  22.10.2015              33       25     7187      299.00   \n",
       "2935832  26.10.2015              33       25     7484      299.00   \n",
       "2935833  22.10.2015              33       25     7308      349.00   \n",
       "2935834  29.10.2015              33       25     7235      298.00   \n",
       "2935835  18.10.2015              33       25     7327      349.00   \n",
       "2935836  22.10.2015              33       25     7327      349.00   \n",
       "2935837  24.10.2015              33       25     7328      249.00   \n",
       "2935838  17.10.2015              33       25     7338      349.00   \n",
       "2935839  24.10.2015              33       25     7315      399.00   \n",
       "2935840  31.10.2015              33       25     7409      299.00   \n",
       "2935841  11.10.2015              33       25     7393      349.00   \n",
       "2935842  10.10.2015              33       25     7384      749.00   \n",
       "2935843  09.10.2015              33       25     7409      299.00   \n",
       "2935844  10.10.2015              33       25     7409      299.00   \n",
       "2935845  09.10.2015              33       25     7460      299.00   \n",
       "2935846  14.10.2015              33       25     7459      349.00   \n",
       "2935847  22.10.2015              33       25     7440      299.00   \n",
       "2935848  03.10.2015              33       25     7460      299.00   \n",
       "\n",
       "         item_cnt_day  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                -1.0  \n",
       "3                 1.0  \n",
       "4                 1.0  \n",
       "5                 1.0  \n",
       "6                 1.0  \n",
       "7                 1.0  \n",
       "8                 1.0  \n",
       "9                 3.0  \n",
       "10                2.0  \n",
       "11                1.0  \n",
       "12                1.0  \n",
       "13                2.0  \n",
       "14                1.0  \n",
       "15                2.0  \n",
       "16                1.0  \n",
       "17                1.0  \n",
       "18                1.0  \n",
       "19                1.0  \n",
       "20                1.0  \n",
       "21                1.0  \n",
       "22                1.0  \n",
       "23                1.0  \n",
       "24                1.0  \n",
       "25                1.0  \n",
       "26                1.0  \n",
       "27                1.0  \n",
       "28                1.0  \n",
       "29                1.0  \n",
       "...               ...  \n",
       "2935819           1.0  \n",
       "2935820           1.0  \n",
       "2935821           1.0  \n",
       "2935822           1.0  \n",
       "2935823           1.0  \n",
       "2935824           1.0  \n",
       "2935825           1.0  \n",
       "2935826           1.0  \n",
       "2935827           1.0  \n",
       "2935828           1.0  \n",
       "2935829           1.0  \n",
       "2935830           1.0  \n",
       "2935831           1.0  \n",
       "2935832           1.0  \n",
       "2935833           1.0  \n",
       "2935834           1.0  \n",
       "2935835           1.0  \n",
       "2935836           1.0  \n",
       "2935837           1.0  \n",
       "2935838           1.0  \n",
       "2935839           1.0  \n",
       "2935840           1.0  \n",
       "2935841           1.0  \n",
       "2935842           1.0  \n",
       "2935843           1.0  \n",
       "2935844           1.0  \n",
       "2935845           1.0  \n",
       "2935846           1.0  \n",
       "2935847           1.0  \n",
       "2935848           1.0  \n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>4874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>4892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>5823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>5814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>5907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214170</th>\n",
       "      <td>214170</td>\n",
       "      <td>45</td>\n",
       "      <td>14543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214171</th>\n",
       "      <td>214171</td>\n",
       "      <td>45</td>\n",
       "      <td>19253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214172</th>\n",
       "      <td>214172</td>\n",
       "      <td>45</td>\n",
       "      <td>17957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214173</th>\n",
       "      <td>214173</td>\n",
       "      <td>45</td>\n",
       "      <td>12470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214174</th>\n",
       "      <td>214174</td>\n",
       "      <td>45</td>\n",
       "      <td>7543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214175</th>\n",
       "      <td>214175</td>\n",
       "      <td>45</td>\n",
       "      <td>6661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214176</th>\n",
       "      <td>214176</td>\n",
       "      <td>45</td>\n",
       "      <td>11137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214177</th>\n",
       "      <td>214177</td>\n",
       "      <td>45</td>\n",
       "      <td>11489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214178</th>\n",
       "      <td>214178</td>\n",
       "      <td>45</td>\n",
       "      <td>9782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214179</th>\n",
       "      <td>214179</td>\n",
       "      <td>45</td>\n",
       "      <td>2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214180</th>\n",
       "      <td>214180</td>\n",
       "      <td>45</td>\n",
       "      <td>19889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214181</th>\n",
       "      <td>214181</td>\n",
       "      <td>45</td>\n",
       "      <td>20650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214182</th>\n",
       "      <td>214182</td>\n",
       "      <td>45</td>\n",
       "      <td>5665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214183</th>\n",
       "      <td>214183</td>\n",
       "      <td>45</td>\n",
       "      <td>9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214184</th>\n",
       "      <td>214184</td>\n",
       "      <td>45</td>\n",
       "      <td>10767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214185</th>\n",
       "      <td>214185</td>\n",
       "      <td>45</td>\n",
       "      <td>14443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214186</th>\n",
       "      <td>214186</td>\n",
       "      <td>45</td>\n",
       "      <td>14341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214187</th>\n",
       "      <td>214187</td>\n",
       "      <td>45</td>\n",
       "      <td>5401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214188</th>\n",
       "      <td>214188</td>\n",
       "      <td>45</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214189</th>\n",
       "      <td>214189</td>\n",
       "      <td>45</td>\n",
       "      <td>16007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214190</th>\n",
       "      <td>214190</td>\n",
       "      <td>45</td>\n",
       "      <td>3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214191</th>\n",
       "      <td>214191</td>\n",
       "      <td>45</td>\n",
       "      <td>4393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214192</th>\n",
       "      <td>214192</td>\n",
       "      <td>45</td>\n",
       "      <td>4352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214193</th>\n",
       "      <td>214193</td>\n",
       "      <td>45</td>\n",
       "      <td>18049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214194</th>\n",
       "      <td>214194</td>\n",
       "      <td>45</td>\n",
       "      <td>18027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  shop_id  item_id\n",
       "0            0        5     5037\n",
       "1            1        5     5320\n",
       "2            2        5     5233\n",
       "3            3        5     5232\n",
       "4            4        5     5268\n",
       "5            5        5     5039\n",
       "6            6        5     5041\n",
       "7            7        5     5046\n",
       "8            8        5     5319\n",
       "9            9        5     5003\n",
       "10          10        5     4806\n",
       "11          11        5     4843\n",
       "12          12        5     4607\n",
       "13          13        5     4869\n",
       "14          14        5     4870\n",
       "15          15        5     4872\n",
       "16          16        5     4874\n",
       "17          17        5     4678\n",
       "18          18        5     4892\n",
       "19          19        5     4964\n",
       "20          20        5     4717\n",
       "21          21        5     5002\n",
       "22          22        5     5823\n",
       "23          23        5     5814\n",
       "24          24        5     5900\n",
       "25          25        5     5907\n",
       "26          26        5     5908\n",
       "27          27        5     5643\n",
       "28          28        5     5657\n",
       "29          29        5     5675\n",
       "...        ...      ...      ...\n",
       "214170  214170       45    14543\n",
       "214171  214171       45    19253\n",
       "214172  214172       45    17957\n",
       "214173  214173       45    12470\n",
       "214174  214174       45     7543\n",
       "214175  214175       45     6661\n",
       "214176  214176       45    11137\n",
       "214177  214177       45    11489\n",
       "214178  214178       45     9782\n",
       "214179  214179       45     2972\n",
       "214180  214180       45    19889\n",
       "214181  214181       45    20650\n",
       "214182  214182       45     5665\n",
       "214183  214183       45     9978\n",
       "214184  214184       45    10767\n",
       "214185  214185       45    14443\n",
       "214186  214186       45    14341\n",
       "214187  214187       45     5401\n",
       "214188  214188       45     9500\n",
       "214189  214189       45    16007\n",
       "214190  214190       45     3280\n",
       "214191  214191       45     4393\n",
       "214192  214192       45     4352\n",
       "214193  214193       45    18049\n",
       "214194  214194       45    18027\n",
       "214195  214195       45    18454\n",
       "214196  214196       45    16188\n",
       "214197  214197       45    15757\n",
       "214198  214198       45    19648\n",
       "214199  214199       45      969\n",
       "\n",
       "[214200 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2935849 entries, 0 to 2935848\n",
      "Data columns (total 6 columns):\n",
      "date              object\n",
      "date_block_num    int64\n",
      "shop_id           int64\n",
      "item_id           int64\n",
      "item_price        float64\n",
      "item_cnt_day      float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 134.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "date_block_num    0\n",
       "shop_id           0\n",
       "item_id           0\n",
       "item_price        0\n",
       "item_cnt_day      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              06.01.2013\n",
       "date_block_num             0\n",
       "shop_id                   25\n",
       "item_id                 2554\n",
       "item_price           1709.05\n",
       "item_cnt_day               1\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    2629372\n",
       " 2.0     194201\n",
       " 3.0      47350\n",
       " 4.0      19685\n",
       " 5.0      10474\n",
       "-1.0       7252\n",
       " 6.0       6338\n",
       " 7.0       4057\n",
       " 8.0       2903\n",
       " 9.0       2177\n",
       "Name: item_cnt_day, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['item_cnt_day'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date']=pd.to_datetime(train['date'])\n",
    "train['year'] = pd.DatetimeIndex(train['date']).year\n",
    "train['month'] = pd.DatetimeIndex(train['date']).month\n",
    "train['day'] = pd.DatetimeIndex(train['date']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2564</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2565</td>\n",
       "      <td>549.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>239.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2573</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2593</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2609</td>\n",
       "      <td>1699.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2548</td>\n",
       "      <td>1708.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2611</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2546</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2515</td>\n",
       "      <td>1649.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935819</th>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7789</td>\n",
       "      <td>1799.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935820</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7790</td>\n",
       "      <td>799.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935821</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7791</td>\n",
       "      <td>899.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935822</th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7632</td>\n",
       "      <td>2310.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935823</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7487</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935824</th>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7029</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935825</th>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935826</th>\n",
       "      <td>2015-04-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935827</th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935828</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>479.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935829</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935830</th>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7286</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935831</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7187</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935832</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7484</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935833</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935834</th>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7235</td>\n",
       "      <td>298.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935835</th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935836</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935837</th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7328</td>\n",
       "      <td>249.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935838</th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7338</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935839</th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7315</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935840</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935841</th>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7393</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935842</th>\n",
       "      <td>2015-10-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7384</td>\n",
       "      <td>749.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935843</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>2015-10-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  date_block_num  shop_id  item_id  item_price  \\\n",
       "0       2013-02-01               0       59    22154      999.00   \n",
       "1       2013-03-01               0       25     2552      899.00   \n",
       "2       2013-05-01               0       25     2552      899.00   \n",
       "3       2013-06-01               0       25     2554     1709.05   \n",
       "4       2013-01-15               0       25     2555     1099.00   \n",
       "5       2013-10-01               0       25     2564      349.00   \n",
       "6       2013-02-01               0       25     2565      549.00   \n",
       "7       2013-04-01               0       25     2572      239.00   \n",
       "8       2013-11-01               0       25     2572      299.00   \n",
       "9       2013-03-01               0       25     2573      299.00   \n",
       "10      2013-03-01               0       25     2574      399.00   \n",
       "11      2013-05-01               0       25     2574      399.00   \n",
       "12      2013-07-01               0       25     2574      399.00   \n",
       "13      2013-08-01               0       25     2574      399.00   \n",
       "14      2013-10-01               0       25     2574      399.00   \n",
       "15      2013-11-01               0       25     2574      399.00   \n",
       "16      2013-01-13               0       25     2574      399.00   \n",
       "17      2013-01-16               0       25     2574      399.00   \n",
       "18      2013-01-26               0       25     2574      399.00   \n",
       "19      2013-01-27               0       25     2574      399.00   \n",
       "20      2013-09-01               0       25     2593      279.00   \n",
       "21      2013-01-16               0       25     2604      299.00   \n",
       "22      2013-01-27               0       25     2604      299.00   \n",
       "23      2013-01-27               0       25     2607      279.00   \n",
       "24      2013-01-29               0       25     2607      279.00   \n",
       "25      2013-01-27               0       25     2609     1699.00   \n",
       "26      2013-06-01               0       25     2548     1708.95   \n",
       "27      2013-01-26               0       25     2611      299.00   \n",
       "28      2013-02-01               0       25     2546      299.00   \n",
       "29      2013-06-01               0       25     2515     1649.00   \n",
       "...            ...             ...      ...      ...         ...   \n",
       "2935819 2015-10-16              33       25     7789     1799.00   \n",
       "2935820 2015-10-22              33       25     7790      799.00   \n",
       "2935821 2015-10-22              33       25     7791      899.50   \n",
       "2935822 2015-10-17              33       25     7632     2310.00   \n",
       "2935823 2015-10-26              33       25     7487      299.00   \n",
       "2935824 2015-10-14              33       25     7029      999.00   \n",
       "2935825 2015-10-23              33       25     7460      299.00   \n",
       "2935826 2015-04-10              33       25     7233      599.00   \n",
       "2935827 2015-10-18              33       25     7308      349.00   \n",
       "2935828 2015-10-21              33       25     7233      479.00   \n",
       "2935829 2015-03-10              33       25     7233      599.00   \n",
       "2935830 2015-11-10              33       25     7286      299.00   \n",
       "2935831 2015-10-22              33       25     7187      299.00   \n",
       "2935832 2015-10-26              33       25     7484      299.00   \n",
       "2935833 2015-10-22              33       25     7308      349.00   \n",
       "2935834 2015-10-29              33       25     7235      298.00   \n",
       "2935835 2015-10-18              33       25     7327      349.00   \n",
       "2935836 2015-10-22              33       25     7327      349.00   \n",
       "2935837 2015-10-24              33       25     7328      249.00   \n",
       "2935838 2015-10-17              33       25     7338      349.00   \n",
       "2935839 2015-10-24              33       25     7315      399.00   \n",
       "2935840 2015-10-31              33       25     7409      299.00   \n",
       "2935841 2015-11-10              33       25     7393      349.00   \n",
       "2935842 2015-10-10              33       25     7384      749.00   \n",
       "2935843 2015-09-10              33       25     7409      299.00   \n",
       "2935844 2015-10-10              33       25     7409      299.00   \n",
       "2935845 2015-09-10              33       25     7460      299.00   \n",
       "2935846 2015-10-14              33       25     7459      349.00   \n",
       "2935847 2015-10-22              33       25     7440      299.00   \n",
       "2935848 2015-03-10              33       25     7460      299.00   \n",
       "\n",
       "         item_cnt_day  year  month  day  \n",
       "0                 1.0  2013      2    1  \n",
       "1                 1.0  2013      3    1  \n",
       "2                -1.0  2013      5    1  \n",
       "3                 1.0  2013      6    1  \n",
       "4                 1.0  2013      1   15  \n",
       "5                 1.0  2013     10    1  \n",
       "6                 1.0  2013      2    1  \n",
       "7                 1.0  2013      4    1  \n",
       "8                 1.0  2013     11    1  \n",
       "9                 3.0  2013      3    1  \n",
       "10                2.0  2013      3    1  \n",
       "11                1.0  2013      5    1  \n",
       "12                1.0  2013      7    1  \n",
       "13                2.0  2013      8    1  \n",
       "14                1.0  2013     10    1  \n",
       "15                2.0  2013     11    1  \n",
       "16                1.0  2013      1   13  \n",
       "17                1.0  2013      1   16  \n",
       "18                1.0  2013      1   26  \n",
       "19                1.0  2013      1   27  \n",
       "20                1.0  2013      9    1  \n",
       "21                1.0  2013      1   16  \n",
       "22                1.0  2013      1   27  \n",
       "23                1.0  2013      1   27  \n",
       "24                1.0  2013      1   29  \n",
       "25                1.0  2013      1   27  \n",
       "26                1.0  2013      6    1  \n",
       "27                1.0  2013      1   26  \n",
       "28                1.0  2013      2    1  \n",
       "29                1.0  2013      6    1  \n",
       "...               ...   ...    ...  ...  \n",
       "2935819           1.0  2015     10   16  \n",
       "2935820           1.0  2015     10   22  \n",
       "2935821           1.0  2015     10   22  \n",
       "2935822           1.0  2015     10   17  \n",
       "2935823           1.0  2015     10   26  \n",
       "2935824           1.0  2015     10   14  \n",
       "2935825           1.0  2015     10   23  \n",
       "2935826           1.0  2015      4   10  \n",
       "2935827           1.0  2015     10   18  \n",
       "2935828           1.0  2015     10   21  \n",
       "2935829           1.0  2015      3   10  \n",
       "2935830           1.0  2015     11   10  \n",
       "2935831           1.0  2015     10   22  \n",
       "2935832           1.0  2015     10   26  \n",
       "2935833           1.0  2015     10   22  \n",
       "2935834           1.0  2015     10   29  \n",
       "2935835           1.0  2015     10   18  \n",
       "2935836           1.0  2015     10   22  \n",
       "2935837           1.0  2015     10   24  \n",
       "2935838           1.0  2015     10   17  \n",
       "2935839           1.0  2015     10   24  \n",
       "2935840           1.0  2015     10   31  \n",
       "2935841           1.0  2015     11   10  \n",
       "2935842           1.0  2015     10   10  \n",
       "2935843           1.0  2015      9   10  \n",
       "2935844           1.0  2015     10   10  \n",
       "2935845           1.0  2015      9   10  \n",
       "2935846           1.0  2015     10   14  \n",
       "2935847           1.0  2015     10   22  \n",
       "2935848           1.0  2015      3   10  \n",
       "\n",
       "[2935849 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    2629372\n",
       " 2.0     194201\n",
       " 3.0      47350\n",
       " 4.0      19685\n",
       " 5.0      10474\n",
       "-1.0       7252\n",
       " 6.0       6338\n",
       " 7.0       4057\n",
       " 8.0       2903\n",
       " 9.0       2177\n",
       "Name: item_cnt_day, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['item_cnt_day'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    295737\n",
       "2     268750\n",
       "3     266531\n",
       "8     259772\n",
       "1     251230\n",
       "7     246341\n",
       "6     238332\n",
       "5     232856\n",
       "4     231064\n",
       "9     224086\n",
       "10    222682\n",
       "11    198468\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2564</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2565</td>\n",
       "      <td>549.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>239.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2572</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2573</td>\n",
       "      <td>299.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2574</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2593</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2604</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2607</td>\n",
       "      <td>279.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2609</td>\n",
       "      <td>1699.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2548</td>\n",
       "      <td>1708.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2611</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2546</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2515</td>\n",
       "      <td>1649.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935819</th>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7789</td>\n",
       "      <td>1799.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935820</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7790</td>\n",
       "      <td>799.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935821</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7791</td>\n",
       "      <td>899.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935822</th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7632</td>\n",
       "      <td>2310.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935823</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7487</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935824</th>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7029</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935825</th>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935826</th>\n",
       "      <td>2015-04-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935827</th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935828</th>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>479.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935829</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7233</td>\n",
       "      <td>599.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935830</th>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7286</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935831</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7187</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935832</th>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7484</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935833</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7308</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935834</th>\n",
       "      <td>2015-10-29</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7235</td>\n",
       "      <td>298.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935835</th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935836</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7327</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935837</th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7328</td>\n",
       "      <td>249.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935838</th>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7338</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935839</th>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7315</td>\n",
       "      <td>399.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935840</th>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935841</th>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7393</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935842</th>\n",
       "      <td>2015-10-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7384</td>\n",
       "      <td>749.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935843</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>2015-10-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  date_block_num  shop_id  item_id  item_price  \\\n",
       "0       2013-02-01               0       59    22154      999.00   \n",
       "1       2013-03-01               0       25     2552      899.00   \n",
       "2       2013-05-01               0       25     2552      899.00   \n",
       "3       2013-06-01               0       25     2554     1709.05   \n",
       "4       2013-01-15               0       25     2555     1099.00   \n",
       "5       2013-10-01               0       25     2564      349.00   \n",
       "6       2013-02-01               0       25     2565      549.00   \n",
       "7       2013-04-01               0       25     2572      239.00   \n",
       "8       2013-11-01               0       25     2572      299.00   \n",
       "9       2013-03-01               0       25     2573      299.00   \n",
       "10      2013-03-01               0       25     2574      399.00   \n",
       "11      2013-05-01               0       25     2574      399.00   \n",
       "12      2013-07-01               0       25     2574      399.00   \n",
       "13      2013-08-01               0       25     2574      399.00   \n",
       "14      2013-10-01               0       25     2574      399.00   \n",
       "15      2013-11-01               0       25     2574      399.00   \n",
       "16      2013-01-13               0       25     2574      399.00   \n",
       "17      2013-01-16               0       25     2574      399.00   \n",
       "18      2013-01-26               0       25     2574      399.00   \n",
       "19      2013-01-27               0       25     2574      399.00   \n",
       "20      2013-09-01               0       25     2593      279.00   \n",
       "21      2013-01-16               0       25     2604      299.00   \n",
       "22      2013-01-27               0       25     2604      299.00   \n",
       "23      2013-01-27               0       25     2607      279.00   \n",
       "24      2013-01-29               0       25     2607      279.00   \n",
       "25      2013-01-27               0       25     2609     1699.00   \n",
       "26      2013-06-01               0       25     2548     1708.95   \n",
       "27      2013-01-26               0       25     2611      299.00   \n",
       "28      2013-02-01               0       25     2546      299.00   \n",
       "29      2013-06-01               0       25     2515     1649.00   \n",
       "...            ...             ...      ...      ...         ...   \n",
       "2935819 2015-10-16              33       25     7789     1799.00   \n",
       "2935820 2015-10-22              33       25     7790      799.00   \n",
       "2935821 2015-10-22              33       25     7791      899.50   \n",
       "2935822 2015-10-17              33       25     7632     2310.00   \n",
       "2935823 2015-10-26              33       25     7487      299.00   \n",
       "2935824 2015-10-14              33       25     7029      999.00   \n",
       "2935825 2015-10-23              33       25     7460      299.00   \n",
       "2935826 2015-04-10              33       25     7233      599.00   \n",
       "2935827 2015-10-18              33       25     7308      349.00   \n",
       "2935828 2015-10-21              33       25     7233      479.00   \n",
       "2935829 2015-03-10              33       25     7233      599.00   \n",
       "2935830 2015-11-10              33       25     7286      299.00   \n",
       "2935831 2015-10-22              33       25     7187      299.00   \n",
       "2935832 2015-10-26              33       25     7484      299.00   \n",
       "2935833 2015-10-22              33       25     7308      349.00   \n",
       "2935834 2015-10-29              33       25     7235      298.00   \n",
       "2935835 2015-10-18              33       25     7327      349.00   \n",
       "2935836 2015-10-22              33       25     7327      349.00   \n",
       "2935837 2015-10-24              33       25     7328      249.00   \n",
       "2935838 2015-10-17              33       25     7338      349.00   \n",
       "2935839 2015-10-24              33       25     7315      399.00   \n",
       "2935840 2015-10-31              33       25     7409      299.00   \n",
       "2935841 2015-11-10              33       25     7393      349.00   \n",
       "2935842 2015-10-10              33       25     7384      749.00   \n",
       "2935843 2015-09-10              33       25     7409      299.00   \n",
       "2935844 2015-10-10              33       25     7409      299.00   \n",
       "2935845 2015-09-10              33       25     7460      299.00   \n",
       "2935846 2015-10-14              33       25     7459      349.00   \n",
       "2935847 2015-10-22              33       25     7440      299.00   \n",
       "2935848 2015-03-10              33       25     7460      299.00   \n",
       "\n",
       "         item_cnt_day  year  month  day  \n",
       "0                 1.0  2013      2    1  \n",
       "1                 1.0  2013      3    1  \n",
       "2                -1.0  2013      5    1  \n",
       "3                 1.0  2013      6    1  \n",
       "4                 1.0  2013      1   15  \n",
       "5                 1.0  2013     10    1  \n",
       "6                 1.0  2013      2    1  \n",
       "7                 1.0  2013      4    1  \n",
       "8                 1.0  2013     11    1  \n",
       "9                 3.0  2013      3    1  \n",
       "10                2.0  2013      3    1  \n",
       "11                1.0  2013      5    1  \n",
       "12                1.0  2013      7    1  \n",
       "13                2.0  2013      8    1  \n",
       "14                1.0  2013     10    1  \n",
       "15                2.0  2013     11    1  \n",
       "16                1.0  2013      1   13  \n",
       "17                1.0  2013      1   16  \n",
       "18                1.0  2013      1   26  \n",
       "19                1.0  2013      1   27  \n",
       "20                1.0  2013      9    1  \n",
       "21                1.0  2013      1   16  \n",
       "22                1.0  2013      1   27  \n",
       "23                1.0  2013      1   27  \n",
       "24                1.0  2013      1   29  \n",
       "25                1.0  2013      1   27  \n",
       "26                1.0  2013      6    1  \n",
       "27                1.0  2013      1   26  \n",
       "28                1.0  2013      2    1  \n",
       "29                1.0  2013      6    1  \n",
       "...               ...   ...    ...  ...  \n",
       "2935819           1.0  2015     10   16  \n",
       "2935820           1.0  2015     10   22  \n",
       "2935821           1.0  2015     10   22  \n",
       "2935822           1.0  2015     10   17  \n",
       "2935823           1.0  2015     10   26  \n",
       "2935824           1.0  2015     10   14  \n",
       "2935825           1.0  2015     10   23  \n",
       "2935826           1.0  2015      4   10  \n",
       "2935827           1.0  2015     10   18  \n",
       "2935828           1.0  2015     10   21  \n",
       "2935829           1.0  2015      3   10  \n",
       "2935830           1.0  2015     11   10  \n",
       "2935831           1.0  2015     10   22  \n",
       "2935832           1.0  2015     10   26  \n",
       "2935833           1.0  2015     10   22  \n",
       "2935834           1.0  2015     10   29  \n",
       "2935835           1.0  2015     10   18  \n",
       "2935836           1.0  2015     10   22  \n",
       "2935837           1.0  2015     10   24  \n",
       "2935838           1.0  2015     10   17  \n",
       "2935839           1.0  2015     10   24  \n",
       "2935840           1.0  2015     10   31  \n",
       "2935841           1.0  2015     11   10  \n",
       "2935842           1.0  2015     10   10  \n",
       "2935843           1.0  2015      9   10  \n",
       "2935844           1.0  2015     10   10  \n",
       "2935845           1.0  2015      9   10  \n",
       "2935846           1.0  2015     10   14  \n",
       "2935847           1.0  2015     10   22  \n",
       "2935848           1.0  2015      3   10  \n",
       "\n",
       "[2935849 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train.groupby('month')['item_cnt_day'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2013\n",
       "1          2013\n",
       "2          2013\n",
       "3          2013\n",
       "4          2013\n",
       "5          2013\n",
       "6          2013\n",
       "7          2013\n",
       "8          2013\n",
       "9          2013\n",
       "10         2013\n",
       "11         2013\n",
       "12         2013\n",
       "13         2013\n",
       "14         2013\n",
       "15         2013\n",
       "16         2013\n",
       "17         2013\n",
       "18         2013\n",
       "19         2013\n",
       "20         2013\n",
       "21         2013\n",
       "22         2013\n",
       "23         2013\n",
       "24         2013\n",
       "25         2013\n",
       "26         2013\n",
       "27         2013\n",
       "28         2013\n",
       "29         2013\n",
       "           ... \n",
       "2935819    2015\n",
       "2935820    2015\n",
       "2935821    2015\n",
       "2935822    2015\n",
       "2935823    2015\n",
       "2935824    2015\n",
       "2935825    2015\n",
       "2935826    2015\n",
       "2935827    2015\n",
       "2935828    2015\n",
       "2935829    2015\n",
       "2935830    2015\n",
       "2935831    2015\n",
       "2935832    2015\n",
       "2935833    2015\n",
       "2935834    2015\n",
       "2935835    2015\n",
       "2935836    2015\n",
       "2935837    2015\n",
       "2935838    2015\n",
       "2935839    2015\n",
       "2935840    2015\n",
       "2935841    2015\n",
       "2935842    2015\n",
       "2935843    2015\n",
       "2935844    2015\n",
       "2935845    2015\n",
       "2935846    2015\n",
       "2935847    2015\n",
       "2935848    2015\n",
       "Name: year, Length: 2935849, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train[(train['month']==1)&(train['year']==2013)]['item_price'].sum()\n",
    "ab=train[(train['month']==1)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "b=train[(train['month']==1)&(train['year']==2014)]['item_price'].sum()\n",
    "bc=train[(train['month']==1)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "c=train[(train['month']==1)&(train['year']==2015)]['item_price'].sum()\n",
    "cd=train[(train['month']==1)&(train['year']==2015)]['item_price'].sum()\n",
    "aw=a*ab\n",
    "bw=b*bc\n",
    "cw=c*cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=train[(train['month']==2)&(train['year']==2013)]['item_price'].sum()\n",
    "de=train[(train['month']==2)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "e=train[(train['month']==2)&(train['year']==2014)]['item_price'].sum()\n",
    "ef=train[(train['month']==2)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "f=train[(train['month']==2)&(train['year']==2015)]['item_price'].sum()\n",
    "fg=train[(train['month']==2)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "dw=d*de\n",
    "ew=e*ef\n",
    "fw=f*fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=train[(train['month']==3)&(train['year']==2013)]['item_price'].sum()\n",
    "gh=train[(train['month']==3)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "h=train[(train['month']==3)&(train['year']==2014)]['item_price'].sum()\n",
    "hi=train[(train['month']==3)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "i=train[(train['month']==3)&(train['year']==2015)]['item_price'].sum()\n",
    "ij=train[(train['month']==3)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "gw=g*gh\n",
    "hw=h*hi\n",
    "iw=i*ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=train[(train['month']==4)&(train['year']==2013)]['item_price'].sum()\n",
    "jk=train[(train['month']==4)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "k=train[(train['month']==4)&(train['year']==2014)]['item_price'].sum()\n",
    "kl=train[(train['month']==4)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "l=train[(train['month']==4)&(train['year']==2015)]['item_price'].sum()\n",
    "lm=train[(train['month']==4)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "jw=j*jk\n",
    "kw=k*kl\n",
    "lw=l*lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=train[(train['month']==5)&(train['year']==2013)]['item_price'].sum()\n",
    "mn=train[(train['month']==5)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "n=train[(train['month']==5)&(train['year']==2014)]['item_price'].sum()\n",
    "no=train[(train['month']==5)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "o=train[(train['month']==5)&(train['year']==2015)]['item_price'].sum()\n",
    "op=train[(train['month']==5)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "mw=m*mn\n",
    "nw=n*no\n",
    "ow=o*op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=train[(train['month']==6)&(train['year']==2013)]['item_price'].sum()\n",
    "pq=train[(train['month']==6)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "q=train[(train['month']==6)&(train['year']==2014)]['item_price'].sum()\n",
    "qr=train[(train['month']==6)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "r=train[(train['month']==6)&(train['year']==2015)]['item_price'].sum()\n",
    "rs=train[(train['month']==6)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "pw=p*pq\n",
    "qw=q*qr\n",
    "rw=r*rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=train[(train['month']==7)&(train['year']==2013)]['item_price'].sum()\n",
    "st=train[(train['month']==7)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "t=train[(train['month']==7)&(train['year']==2014)]['item_price'].sum()\n",
    "tu=train[(train['month']==7)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "u=train[(train['month']==7)&(train['year']==2015)]['item_price'].sum()\n",
    "uv=train[(train['month']==7)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "sw=s*st\n",
    "tw=t*tu\n",
    "uw=u*uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=train[(train['month']==8)&(train['year']==2013)]['item_price'].sum()\n",
    "vww=train[(train['month']==8)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "w=train[(train['month']==8)&(train['year']==2014)]['item_price'].sum()\n",
    "wx=train[(train['month']==8)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "x=train[(train['month']==8)&(train['year']==2015)]['item_price'].sum()\n",
    "xy=train[(train['month']==8)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "vw=v*vww\n",
    "ww=w*wx\n",
    "xw=x*xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train[(train['month']==9)&(train['year']==2013)]['item_price'].sum()\n",
    "yz=train[(train['month']==9)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "z=train[(train['month']==9)&(train['year']==2014)]['item_price'].sum()\n",
    "zaa=train[(train['month']==9)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "aa=train[(train['month']==9)&(train['year']==2015)]['item_price'].sum()\n",
    "aabb=train[(train['month']==9)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "yw=y*yz\n",
    "zw=z*zaa\n",
    "aaw=aa*aabb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=train[(train['month']==10)&(train['year']==2013)]['item_price'].sum()\n",
    "bbcc=train[(train['month']==10)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "cc=train[(train['month']==10)&(train['year']==2014)]['item_price'].sum()\n",
    "ccdd=train[(train['month']==10)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "dd=train[(train['month']==10)&(train['year']==2015)]['item_price'].sum()\n",
    "ddee=train[(train['month']==10)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "bbw=bb*bbcc\n",
    "ccw=cc*ccdd\n",
    "ddw=dd*ddee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee=train[(train['month']==11)&(train['year']==2013)]['item_price'].sum()\n",
    "eeff=train[(train['month']==11)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "ff=train[(train['month']==11)&(train['year']==2014)]['item_price'].sum()\n",
    "ffgg=train[(train['month']==11)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "gg=train[(train['month']==11)&(train['year']==2015)]['item_price'].sum()\n",
    "gghh=train[(train['month']==11)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "eew=ee*eeff\n",
    "ffw=ff*ffgg\n",
    "ggw=gg*gghh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=train[(train['month']==12)&(train['year']==2013)]['item_price'].sum()\n",
    "hhii=train[(train['month']==12)&(train['year']==2013)]['item_cnt_day'].sum()\n",
    "ii=train[(train['month']==12)&(train['year']==2014)]['item_price'].sum()\n",
    "iijj=train[(train['month']==12)&(train['year']==2014)]['item_cnt_day'].sum()\n",
    "jj=train[(train['month']==12)&(train['year']==2015)]['item_price'].sum()\n",
    "jjkk=train[(train['month']==12)&(train['year']==2015)]['item_cnt_day'].sum()\n",
    "hhw=hh*hhii\n",
    "iiw=ii*iijj\n",
    "jjw=jj*jjkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gt={'Month':(1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2013),(12)),\n",
    "    'price':[aw,dw,gw,jw,mw,pw,sw,vw,yw,bbw,eew,hhw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gt, columns = ['Month', 'year','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.256824e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.045823e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.140109e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.187237e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.423285e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.748351e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.044152e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.517558e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.000887e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.561598e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.454004e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.468495e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year         price\n",
       "0       1  2013  8.256824e+12\n",
       "1       2  2013  1.045823e+13\n",
       "2       3  2013  1.140109e+13\n",
       "3       4  2013  7.187237e+12\n",
       "4       5  2013  7.423285e+12\n",
       "5       6  2013  8.748351e+12\n",
       "6       7  2013  9.044152e+12\n",
       "7       8  2013  9.517558e+12\n",
       "8       9  2013  1.000887e+13\n",
       "9      10  2013  8.561598e+12\n",
       "10     11  2013  8.454004e+12\n",
       "11     12  2013  2.468495e+13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tb={'Month':(1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2014),(12)),\n",
    "    'price':[bw,ew,hw,kw,nw,qw,tw,ww,zw,ccw,ffw,iiw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(tb, columns = ['Month', 'year','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.540134e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.874175e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.321144e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.406712e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.308169e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.605569e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>6.996897e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.137587e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.317776e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>6.768443e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.171049e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>2.865075e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year         price\n",
       "0       1  2014  7.540134e+12\n",
       "1       2  2014  8.874175e+12\n",
       "2       3  2014  9.321144e+12\n",
       "3       4  2014  7.406712e+12\n",
       "4       5  2014  8.308169e+12\n",
       "5       6  2014  7.605569e+12\n",
       "6       7  2014  6.996897e+12\n",
       "7       8  2014  9.137587e+12\n",
       "8       9  2014  8.317776e+12\n",
       "9      10  2014  6.768443e+12\n",
       "10     11  2014  1.171049e+13\n",
       "11     12  2014  2.865075e+13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tj={'Month':(1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2015),(12)),\n",
    "    'price':[cw,fw,iw,lw,ow,rw,uw,xw,aaw,ddw,ggw,jjw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(tj, columns = ['Month', 'year','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.971789e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.694661e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.177621e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.693508e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.496799e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.491055e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.506124e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.995368e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.601153e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.977924e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.484514e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.922644e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year         price\n",
       "0       1  2015  4.971789e+15\n",
       "1       2  2015  5.694661e+12\n",
       "2       3  2015  5.177621e+12\n",
       "3       4  2015  4.693508e+12\n",
       "4       5  2015  4.496799e+12\n",
       "5       6  2015  3.491055e+12\n",
       "6       7  2015  3.506124e+12\n",
       "7       8  2015  3.995368e+12\n",
       "8       9  2015  3.601153e+12\n",
       "9      10  2015  3.977924e+12\n",
       "10     11  2015  5.484514e+11\n",
       "11     12  2015  3.922644e+11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114bbdb00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114c7e828>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df1,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114c7e940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df2,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.200000e+01\n",
       "mean     1.031218e+13\n",
       "std      4.684727e+12\n",
       "min      7.187237e+12\n",
       "25%      8.404709e+12\n",
       "50%      8.896252e+12\n",
       "75%      1.012121e+13\n",
       "max      2.468495e+13\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.200000e+01\n",
       "mean     1.005315e+13\n",
       "std      6.006643e+12\n",
       "min      6.768443e+12\n",
       "25%      7.506778e+12\n",
       "50%      8.312973e+12\n",
       "75%      9.183476e+12\n",
       "max      2.865075e+13\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.200000e+01\n",
       "mean     4.176137e+14\n",
       "std      1.434194e+15\n",
       "min      3.922644e+11\n",
       "25%      3.502357e+12\n",
       "50%      3.986646e+12\n",
       "75%      4.814536e+12\n",
       "max      4.971789e+15\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['price']=np.log(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.742061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.978410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>30.064730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.603328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.635643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.799886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.833139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.884159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.934493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.778308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.765661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>30.837215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year      price\n",
       "0       1  2013  29.742061\n",
       "1       2  2013  29.978410\n",
       "2       3  2013  30.064730\n",
       "3       4  2013  29.603328\n",
       "4       5  2013  29.635643\n",
       "5       6  2013  29.799886\n",
       "6       7  2013  29.833139\n",
       "7       8  2013  29.884159\n",
       "8       9  2013  29.934493\n",
       "9      10  2013  29.778308\n",
       "10     11  2013  29.765661\n",
       "11     12  2013  30.837215"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df1['price']=np.log(df1['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df2['price']=np.log(df2['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.904753\n",
       "std       0.322352\n",
       "min      29.603328\n",
       "25%      29.759761\n",
       "50%      29.816513\n",
       "75%      29.945472\n",
       "max      30.837215\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.846719\n",
       "std       0.388768\n",
       "min      29.543292\n",
       "25%      29.646798\n",
       "50%      29.748838\n",
       "75%      29.848390\n",
       "max      30.986201\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.294383\n",
       "std       2.325073\n",
       "min      26.695202\n",
       "25%      28.884455\n",
       "50%      29.013969\n",
       "75%      29.201743\n",
       "max      36.142556\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10de3cb00>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10deae9e8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df1,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114e7dc50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(x='Month',y='price',data=df2,palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.904753\n",
       "std       0.322352\n",
       "min      29.603328\n",
       "25%      29.759761\n",
       "50%      29.816513\n",
       "75%      29.945472\n",
       "max      30.837215\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.846719\n",
       "std       0.388768\n",
       "min      29.543292\n",
       "25%      29.646798\n",
       "50%      29.748838\n",
       "75%      29.848390\n",
       "max      30.986201\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     29.294383\n",
       "std       2.325073\n",
       "min      26.695202\n",
       "25%      28.884455\n",
       "50%      29.013969\n",
       "75%      29.201743\n",
       "max      36.142556\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tb={'Month':(1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2014),(12)),\n",
    "    'price':[bw,ew,hw,kw,nw,qw,tw,ww,zw,ccw,ffw,iiw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tj={'Month':(1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2015),(12)),\n",
    "    'price':[cw,fw,iw,lw,ow,rw,uw,xw,aaw,ddw,ggw,jjw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "adg={'Month':(1,2,3,4,5,6,7,8,9,10,11,12,1,2,3,4,5,6,7,8,9,10,11,12,1,2,3,4,5,6,7,8,9,10,11,12),\n",
    "    'year': np.repeat((2013,2014,2015),(12,12,12)),\n",
    "    'price':[aw,dw,gw,jw,mw,pw,sw,vw,yw,bbw,eew,hhw,bw,ew,hw,kw,nw,qw,tw,ww,zw,ccw,ffw,iiw,cw,fw,iw,lw,ow,rw,uw,xw,aaw,ddw,ggw,jjw]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(adg, columns = ['Month', 'year','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.256824e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.045823e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.140109e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.187237e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.423285e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.748351e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.044152e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.517558e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.000887e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.561598e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.454004e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.468495e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.540134e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.874175e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.321144e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.406712e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.308169e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.605569e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>6.996897e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.137587e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.317776e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>6.768443e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.171049e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>2.865075e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.971789e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.694661e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.177621e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.693508e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.496799e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.491055e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.506124e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.995368e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.601153e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.977924e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.484514e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.922644e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year         price\n",
       "0       1  2013  8.256824e+12\n",
       "1       2  2013  1.045823e+13\n",
       "2       3  2013  1.140109e+13\n",
       "3       4  2013  7.187237e+12\n",
       "4       5  2013  7.423285e+12\n",
       "5       6  2013  8.748351e+12\n",
       "6       7  2013  9.044152e+12\n",
       "7       8  2013  9.517558e+12\n",
       "8       9  2013  1.000887e+13\n",
       "9      10  2013  8.561598e+12\n",
       "10     11  2013  8.454004e+12\n",
       "11     12  2013  2.468495e+13\n",
       "12      1  2014  7.540134e+12\n",
       "13      2  2014  8.874175e+12\n",
       "14      3  2014  9.321144e+12\n",
       "15      4  2014  7.406712e+12\n",
       "16      5  2014  8.308169e+12\n",
       "17      6  2014  7.605569e+12\n",
       "18      7  2014  6.996897e+12\n",
       "19      8  2014  9.137587e+12\n",
       "20      9  2014  8.317776e+12\n",
       "21     10  2014  6.768443e+12\n",
       "22     11  2014  1.171049e+13\n",
       "23     12  2014  2.865075e+13\n",
       "24      1  2015  4.971789e+15\n",
       "25      2  2015  5.694661e+12\n",
       "26      3  2015  5.177621e+12\n",
       "27      4  2015  4.693508e+12\n",
       "28      5  2015  4.496799e+12\n",
       "29      6  2015  3.491055e+12\n",
       "30      7  2015  3.506124e+12\n",
       "31      8  2015  3.995368e+12\n",
       "32      9  2015  3.601153e+12\n",
       "33     10  2015  3.977924e+12\n",
       "34     11  2015  5.484514e+11\n",
       "35     12  2015  3.922644e+11"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['price']=np.log(df3['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.742061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.978410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>30.064730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.603328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.635643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.799886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.833139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.884159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.934493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.778308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.765661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>30.837215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.814167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.863307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.633408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.748260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.659902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.576488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.843417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.749416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.543292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>2014</td>\n",
       "      <td>30.091506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>30.986201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>36.142556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.370550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.275367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.177201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.134387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>28.881225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>28.885532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.016157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>28.912275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.011781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>27.030365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>26.695202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  year      price\n",
       "0       1  2013  29.742061\n",
       "1       2  2013  29.978410\n",
       "2       3  2013  30.064730\n",
       "3       4  2013  29.603328\n",
       "4       5  2013  29.635643\n",
       "5       6  2013  29.799886\n",
       "6       7  2013  29.833139\n",
       "7       8  2013  29.884159\n",
       "8       9  2013  29.934493\n",
       "9      10  2013  29.778308\n",
       "10     11  2013  29.765661\n",
       "11     12  2013  30.837215\n",
       "12      1  2014  29.651261\n",
       "13      2  2014  29.814167\n",
       "14      3  2014  29.863307\n",
       "15      4  2014  29.633408\n",
       "16      5  2014  29.748260\n",
       "17      6  2014  29.659902\n",
       "18      7  2014  29.576488\n",
       "19      8  2014  29.843417\n",
       "20      9  2014  29.749416\n",
       "21     10  2014  29.543292\n",
       "22     11  2014  30.091506\n",
       "23     12  2014  30.986201\n",
       "24      1  2015  36.142556\n",
       "25      2  2015  29.370550\n",
       "26      3  2015  29.275367\n",
       "27      4  2015  29.177201\n",
       "28      5  2015  29.134387\n",
       "29      6  2015  28.881225\n",
       "30      7  2015  28.885532\n",
       "31      8  2015  29.016157\n",
       "32      9  2015  28.912275\n",
       "33     10  2015  29.011781\n",
       "34     11  2015  27.030365\n",
       "35     12  2015  26.695202"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas to Numpy for Keras\n",
    "\n",
    "# Features\n",
    "X = df3[['Month','year']].values\n",
    "\n",
    "# Label\n",
    "y = df3['price'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(1,36,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.reshape(1,25,2)\n",
    "X_test.reshape(1,11,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LSTM in module tensorflow.python.keras.layers.recurrent:\n",
      "\n",
      "class LSTM(RNN)\n",
      " |  LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)\n",
      " |  \n",
      " |  Long Short-Term Memory layer - Hochreiter 1997.\n",
      " |  \n",
      " |   Note that this cell is not optimized for performance on GPU. Please use\n",
      " |  `tf.keras.layers.CuDNNLSTM` for better performance on GPU.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      units: Positive integer, dimensionality of the output space.\n",
      " |      activation: Activation function to use.\n",
      " |          Default: hyperbolic tangent (`tanh`).\n",
      " |          If you pass `None`, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      recurrent_activation: Activation function to use\n",
      " |          for the recurrent step.\n",
      " |          Default: hard sigmoid (`hard_sigmoid`).\n",
      " |          If you pass `None`, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix,\n",
      " |          used for the linear transformation of the inputs..\n",
      " |      recurrent_initializer: Initializer for the `recurrent_kernel`\n",
      " |          weights matrix,\n",
      " |          used for the linear transformation of the recurrent state..\n",
      " |      bias_initializer: Initializer for the bias vector.\n",
      " |      unit_forget_bias: Boolean.\n",
      " |          If True, add 1 to the bias of the forget gate at initialization.\n",
      " |          Setting it to true will also force `bias_initializer=\"zeros\"`.\n",
      " |          This is recommended in [Jozefowicz et\n",
      " |            al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix.\n",
      " |      recurrent_regularizer: Regularizer function applied to\n",
      " |          the `recurrent_kernel` weights matrix.\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\")..\n",
      " |      kernel_constraint: Constraint function applied to\n",
      " |          the `kernel` weights matrix.\n",
      " |      recurrent_constraint: Constraint function applied to\n",
      " |          the `recurrent_kernel` weights matrix.\n",
      " |      bias_constraint: Constraint function applied to the bias vector.\n",
      " |      dropout: Float between 0 and 1.\n",
      " |          Fraction of the units to drop for\n",
      " |          the linear transformation of the inputs.\n",
      " |      recurrent_dropout: Float between 0 and 1.\n",
      " |          Fraction of the units to drop for\n",
      " |          the linear transformation of the recurrent state.\n",
      " |      implementation: Implementation mode, either 1 or 2.\n",
      " |          Mode 1 will structure its operations as a larger number of\n",
      " |          smaller dot products and additions, whereas mode 2 will\n",
      " |          batch them into fewer, larger operations. These modes will\n",
      " |          have different performance profiles on different hardware and\n",
      " |          for different applications.\n",
      " |      return_sequences: Boolean. Whether to return the last output.\n",
      " |          in the output sequence, or the full sequence.\n",
      " |      return_state: Boolean. Whether to return the last state\n",
      " |          in addition to the output.\n",
      " |      go_backwards: Boolean (default False).\n",
      " |          If True, process the input sequence backwards and return the\n",
      " |          reversed sequence.\n",
      " |      stateful: Boolean (default False). If True, the last state\n",
      " |          for each sample at index i in a batch will be used as initial\n",
      " |          state for the sample of index i in the following batch.\n",
      " |      unroll: Boolean (default False).\n",
      " |          If True, the network will be unrolled,\n",
      " |          else a symbolic loop will be used.\n",
      " |          Unrolling can speed-up a RNN,\n",
      " |          although it tends to be more memory-intensive.\n",
      " |          Unrolling is only suitable for short sequences.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LSTM\n",
      " |      RNN\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.training.checkpointable.base.CheckpointableBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, **kwargs)\n",
      " |  \n",
      " |  call(self, inputs, mask=None, training=None, initial_state=None)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  activation\n",
      " |  \n",
      " |  bias_constraint\n",
      " |  \n",
      " |  bias_initializer\n",
      " |  \n",
      " |  bias_regularizer\n",
      " |  \n",
      " |  dropout\n",
      " |  \n",
      " |  implementation\n",
      " |  \n",
      " |  kernel_constraint\n",
      " |  \n",
      " |  kernel_initializer\n",
      " |  \n",
      " |  kernel_regularizer\n",
      " |  \n",
      " |  recurrent_activation\n",
      " |  \n",
      " |  recurrent_constraint\n",
      " |  \n",
      " |  recurrent_dropout\n",
      " |  \n",
      " |  recurrent_initializer\n",
      " |  \n",
      " |  recurrent_regularizer\n",
      " |  \n",
      " |  unit_forget_bias\n",
      " |  \n",
      " |  units\n",
      " |  \n",
      " |  use_bias\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNN:\n",
      " |  \n",
      " |  __call__(self, inputs, initial_state=None, constants=None, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_initial_state(self, inputs)\n",
      " |  \n",
      " |  reset_states(self, states=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RNN:\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  states\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Note that `add_loss` is not supported when executing eagerly. Instead,\n",
      " |      variable regularizers may be added through `add_variable`. Activity\n",
      " |      regularization is not supported directly (but such losses may be returned\n",
      " |      from `Layer.call()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `model.add_metric(BinaryAccuracy(name='acc')(y_true,\n",
      " |          y_pred))`. If aggregation='mean', the given metric tensor will be\n",
      " |          sample-wise reduced using `mean` function. eg, `model.add_metric(\n",
      " |          tf.reduce_mean(outputs), name='output_mean', aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops.\n",
      " |        inputs: If anything other than None is passed, it signals the updates\n",
      " |          are conditional on some of the layer's inputs,\n",
      " |          and thus they should only be run where these inputs are available.\n",
      " |          This is the case for BatchNormalization updates, for instance.\n",
      " |          If None, the updates will be taken into account unconditionally,\n",
      " |          and you are responsible for making sure that any dependency they might\n",
      " |          have is available at runtime.\n",
      " |          A step counter might fall into this category.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer, or gets an existing one; returns it.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: variable name.\n",
      " |        shape: variable shape.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: initializer instance (callable).\n",
      " |        regularizer: regularizer instance (callable).\n",
      " |        trainable: whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      " |          Note, if the current variable scope is marked as non-trainable\n",
      " |          then this parameter is ignored and any added variables are also\n",
      " |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      " |          `synchronization` is set to `ON_READ`.\n",
      " |        constraint: constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Checkpointable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Apply the layer on a input.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.checkpointable.base.CheckpointableBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(25,1,2)\n",
    "X_test=X_test.reshape(11,1,2)\n",
    "X=X.reshape(36,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(100,batch_input_shape=(25,1,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "25/25 [==============================] - 1s 30ms/sample - loss: 894.7106\n",
      "Epoch 2/300\n",
      "25/25 [==============================] - 0s 267us/sample - loss: 894.2269\n",
      "Epoch 3/300\n",
      "25/25 [==============================] - 0s 192us/sample - loss: 893.7442\n",
      "Epoch 4/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 893.2621\n",
      "Epoch 5/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 892.7804\n",
      "Epoch 6/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 892.2988\n",
      "Epoch 7/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 891.8171\n",
      "Epoch 8/300\n",
      "25/25 [==============================] - 0s 129us/sample - loss: 891.3353\n",
      "Epoch 9/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 890.8530\n",
      "Epoch 10/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 890.3702\n",
      "Epoch 11/300\n",
      "25/25 [==============================] - 0s 150us/sample - loss: 889.8862\n",
      "Epoch 12/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 889.4012\n",
      "Epoch 13/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 888.9147\n",
      "Epoch 14/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 888.4264\n",
      "Epoch 15/300\n",
      "25/25 [==============================] - 0s 173us/sample - loss: 887.9363\n",
      "Epoch 16/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 887.4437\n",
      "Epoch 17/300\n",
      "25/25 [==============================] - 0s 136us/sample - loss: 886.9485\n",
      "Epoch 18/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 886.4503\n",
      "Epoch 19/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 885.9487\n",
      "Epoch 20/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 885.4433\n",
      "Epoch 21/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 884.9340\n",
      "Epoch 22/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 884.4202\n",
      "Epoch 23/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 883.9016\n",
      "Epoch 24/300\n",
      "25/25 [==============================] - 0s 142us/sample - loss: 883.3781\n",
      "Epoch 25/300\n",
      "25/25 [==============================] - 0s 170us/sample - loss: 882.8490\n",
      "Epoch 26/300\n",
      "25/25 [==============================] - 0s 272us/sample - loss: 882.3142\n",
      "Epoch 27/300\n",
      "25/25 [==============================] - 0s 140us/sample - loss: 881.7733\n",
      "Epoch 28/300\n",
      "25/25 [==============================] - 0s 140us/sample - loss: 881.2257\n",
      "Epoch 29/300\n",
      "25/25 [==============================] - 0s 141us/sample - loss: 880.6713\n",
      "Epoch 30/300\n",
      "25/25 [==============================] - 0s 138us/sample - loss: 880.1097\n",
      "Epoch 31/300\n",
      "25/25 [==============================] - 0s 140us/sample - loss: 879.5405\n",
      "Epoch 32/300\n",
      "25/25 [==============================] - 0s 150us/sample - loss: 878.9635\n",
      "Epoch 33/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 878.3783\n",
      "Epoch 34/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 877.7843\n",
      "Epoch 35/300\n",
      "25/25 [==============================] - 0s 192us/sample - loss: 877.1816\n",
      "Epoch 36/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 876.5697\n",
      "Epoch 37/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 875.9483\n",
      "Epoch 38/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 875.3169\n",
      "Epoch 39/300\n",
      "25/25 [==============================] - 0s 135us/sample - loss: 874.6754\n",
      "Epoch 40/300\n",
      "25/25 [==============================] - 0s 138us/sample - loss: 874.0235\n",
      "Epoch 41/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 873.3608\n",
      "Epoch 42/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 872.6871\n",
      "Epoch 43/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 872.0021\n",
      "Epoch 44/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 871.3055\n",
      "Epoch 45/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 870.5969\n",
      "Epoch 46/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 869.8764\n",
      "Epoch 47/300\n",
      "25/25 [==============================] - 0s 173us/sample - loss: 869.1433\n",
      "Epoch 48/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 868.3975\n",
      "Epoch 49/300\n",
      "25/25 [==============================] - 0s 132us/sample - loss: 867.6389\n",
      "Epoch 50/300\n",
      "25/25 [==============================] - 0s 142us/sample - loss: 866.8669\n",
      "Epoch 51/300\n",
      "25/25 [==============================] - 0s 161us/sample - loss: 866.0815\n",
      "Epoch 52/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 865.2825\n",
      "Epoch 53/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 864.4695\n",
      "Epoch 54/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 863.6423\n",
      "Epoch 55/300\n",
      "25/25 [==============================] - 0s 175us/sample - loss: 862.8007\n",
      "Epoch 56/300\n",
      "25/25 [==============================] - 0s 200us/sample - loss: 861.9445\n",
      "Epoch 57/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 861.0734\n",
      "Epoch 58/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 860.1873\n",
      "Epoch 59/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 859.2857\n",
      "Epoch 60/300\n",
      "25/25 [==============================] - 0s 163us/sample - loss: 858.3686\n",
      "Epoch 61/300\n",
      "25/25 [==============================] - 0s 156us/sample - loss: 857.4359\n",
      "Epoch 62/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 856.4872\n",
      "Epoch 63/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 855.5222\n",
      "Epoch 64/300\n",
      "25/25 [==============================] - 0s 181us/sample - loss: 854.5410\n",
      "Epoch 65/300\n",
      "25/25 [==============================] - 0s 202us/sample - loss: 853.5432\n",
      "Epoch 66/300\n",
      "25/25 [==============================] - 0s 163us/sample - loss: 852.5287\n",
      "Epoch 67/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 851.4973\n",
      "Epoch 68/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 850.4487\n",
      "Epoch 69/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 849.3829\n",
      "Epoch 70/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 848.2996\n",
      "Epoch 71/300\n",
      "25/25 [==============================] - 0s 177us/sample - loss: 847.1986\n",
      "Epoch 72/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 846.0798\n",
      "Epoch 73/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 844.9431\n",
      "Epoch 74/300\n",
      "25/25 [==============================] - 0s 161us/sample - loss: 843.7882\n",
      "Epoch 75/300\n",
      "25/25 [==============================] - 0s 175us/sample - loss: 842.6150\n",
      "Epoch 76/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 841.4235\n",
      "Epoch 77/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 840.2131\n",
      "Epoch 78/300\n",
      "25/25 [==============================] - 0s 132us/sample - loss: 838.9842\n",
      "Epoch 79/300\n",
      "25/25 [==============================] - 0s 123us/sample - loss: 837.7364\n",
      "Epoch 80/300\n",
      "25/25 [==============================] - 0s 130us/sample - loss: 836.4695\n",
      "Epoch 81/300\n",
      "25/25 [==============================] - 0s 136us/sample - loss: 835.1834\n",
      "Epoch 82/300\n",
      "25/25 [==============================] - 0s 135us/sample - loss: 833.8782\n",
      "Epoch 83/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 832.5533\n",
      "Epoch 84/300\n",
      "25/25 [==============================] - 0s 172us/sample - loss: 831.2090\n",
      "Epoch 85/300\n",
      "25/25 [==============================] - 0s 189us/sample - loss: 829.8452\n",
      "Epoch 86/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 828.4615\n",
      "Epoch 87/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 827.0579\n",
      "Epoch 88/300\n",
      "25/25 [==============================] - 0s 121us/sample - loss: 825.6344\n",
      "Epoch 89/300\n",
      "25/25 [==============================] - 0s 122us/sample - loss: 824.1909\n",
      "Epoch 90/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 822.7271\n",
      "Epoch 91/300\n",
      "25/25 [==============================] - 0s 133us/sample - loss: 821.2431\n",
      "Epoch 92/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 819.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 818.2141\n",
      "Epoch 94/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 816.6689\n",
      "Epoch 95/300\n",
      "25/25 [==============================] - 0s 214us/sample - loss: 815.1033\n",
      "Epoch 96/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 813.5168\n",
      "Epoch 97/300\n",
      "25/25 [==============================] - 0s 132us/sample - loss: 811.9100\n",
      "Epoch 98/300\n",
      "25/25 [==============================] - 0s 140us/sample - loss: 810.2823\n",
      "Epoch 99/300\n",
      "25/25 [==============================] - 0s 139us/sample - loss: 808.6339\n",
      "Epoch 100/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 806.9649\n",
      "Epoch 101/300\n",
      "25/25 [==============================] - 0s 141us/sample - loss: 805.2749\n",
      "Epoch 102/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 803.5641\n",
      "Epoch 103/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 801.8323\n",
      "Epoch 104/300\n",
      "25/25 [==============================] - 0s 360us/sample - loss: 800.0798\n",
      "Epoch 105/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 798.3063\n",
      "Epoch 106/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 796.5120\n",
      "Epoch 107/300\n",
      "25/25 [==============================] - 0s 160us/sample - loss: 794.6967\n",
      "Epoch 108/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 792.8605\n",
      "Epoch 109/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 791.0034\n",
      "Epoch 110/300\n",
      "25/25 [==============================] - 0s 146us/sample - loss: 789.1254\n",
      "Epoch 111/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 787.2265\n",
      "Epoch 112/300\n",
      "25/25 [==============================] - 0s 216us/sample - loss: 785.3068\n",
      "Epoch 113/300\n",
      "25/25 [==============================] - 0s 200us/sample - loss: 783.3663\n",
      "Epoch 114/300\n",
      "25/25 [==============================] - 0s 174us/sample - loss: 781.4048\n",
      "Epoch 115/300\n",
      "25/25 [==============================] - 0s 180us/sample - loss: 779.4227\n",
      "Epoch 116/300\n",
      "25/25 [==============================] - 0s 139us/sample - loss: 777.4199\n",
      "Epoch 117/300\n",
      "25/25 [==============================] - 0s 167us/sample - loss: 775.3963\n",
      "Epoch 118/300\n",
      "25/25 [==============================] - 0s 160us/sample - loss: 773.3521\n",
      "Epoch 119/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 771.2875\n",
      "Epoch 120/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 769.2022\n",
      "Epoch 121/300\n",
      "25/25 [==============================] - 0s 176us/sample - loss: 767.0966\n",
      "Epoch 122/300\n",
      "25/25 [==============================] - 0s 211us/sample - loss: 764.9705\n",
      "Epoch 123/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 762.8242\n",
      "Epoch 124/300\n",
      "25/25 [==============================] - 0s 146us/sample - loss: 760.6577\n",
      "Epoch 125/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 758.4711\n",
      "Epoch 126/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 756.2643\n",
      "Epoch 127/300\n",
      "25/25 [==============================] - 0s 152us/sample - loss: 754.0377\n",
      "Epoch 128/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 751.7913\n",
      "Epoch 129/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 749.5250\n",
      "Epoch 130/300\n",
      "25/25 [==============================] - 0s 201us/sample - loss: 747.2392\n",
      "Epoch 131/300\n",
      "25/25 [==============================] - 0s 203us/sample - loss: 744.9339\n",
      "Epoch 132/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 742.6092\n",
      "Epoch 133/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 740.2653\n",
      "Epoch 134/300\n",
      "25/25 [==============================] - 0s 138us/sample - loss: 737.9022\n",
      "Epoch 135/300\n",
      "25/25 [==============================] - 0s 163us/sample - loss: 735.5201\n",
      "Epoch 136/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 733.1191\n",
      "Epoch 137/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 730.6995\n",
      "Epoch 138/300\n",
      "25/25 [==============================] - 0s 185us/sample - loss: 728.2612\n",
      "Epoch 139/300\n",
      "25/25 [==============================] - 0s 181us/sample - loss: 725.8046\n",
      "Epoch 140/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 723.3297\n",
      "Epoch 141/300\n",
      "25/25 [==============================] - 0s 187us/sample - loss: 720.8367\n",
      "Epoch 142/300\n",
      "25/25 [==============================] - 0s 136us/sample - loss: 718.3257\n",
      "Epoch 143/300\n",
      "25/25 [==============================] - 0s 168us/sample - loss: 715.7971\n",
      "Epoch 144/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 713.2507\n",
      "Epoch 145/300\n",
      "25/25 [==============================] - 0s 127us/sample - loss: 710.6870\n",
      "Epoch 146/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 708.1061\n",
      "Epoch 147/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 705.5081\n",
      "Epoch 148/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 702.8933\n",
      "Epoch 149/300\n",
      "25/25 [==============================] - 0s 232us/sample - loss: 700.2618\n",
      "Epoch 150/300\n",
      "25/25 [==============================] - 0s 139us/sample - loss: 697.6138\n",
      "Epoch 151/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 694.9495\n",
      "Epoch 152/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 692.2693\n",
      "Epoch 153/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 689.5731\n",
      "Epoch 154/300\n",
      "25/25 [==============================] - 0s 158us/sample - loss: 686.8614\n",
      "Epoch 155/300\n",
      "25/25 [==============================] - 0s 163us/sample - loss: 684.1342\n",
      "Epoch 156/300\n",
      "25/25 [==============================] - 0s 186us/sample - loss: 681.3917\n",
      "Epoch 157/300\n",
      "25/25 [==============================] - 0s 209us/sample - loss: 678.6344\n",
      "Epoch 158/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 675.8622\n",
      "Epoch 159/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 673.0754\n",
      "Epoch 160/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 670.2745\n",
      "Epoch 161/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 667.4595\n",
      "Epoch 162/300\n",
      "25/25 [==============================] - 0s 142us/sample - loss: 664.6306\n",
      "Epoch 163/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 661.7880\n",
      "Epoch 164/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 658.9322\n",
      "Epoch 165/300\n",
      "25/25 [==============================] - 0s 164us/sample - loss: 656.0633\n",
      "Epoch 166/300\n",
      "25/25 [==============================] - 0s 214us/sample - loss: 653.1815\n",
      "Epoch 167/300\n",
      "25/25 [==============================] - 0s 164us/sample - loss: 650.2870\n",
      "Epoch 168/300\n",
      "25/25 [==============================] - 0s 192us/sample - loss: 647.3803\n",
      "Epoch 169/300\n",
      "25/25 [==============================] - 0s 162us/sample - loss: 644.4615\n",
      "Epoch 170/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 641.5308\n",
      "Epoch 171/300\n",
      "25/25 [==============================] - 0s 178us/sample - loss: 638.5886\n",
      "Epoch 172/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 635.6349\n",
      "Epoch 173/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 632.6704\n",
      "Epoch 174/300\n",
      "25/25 [==============================] - 0s 215us/sample - loss: 629.6949\n",
      "Epoch 175/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 626.7090\n",
      "Epoch 176/300\n",
      "25/25 [==============================] - 0s 139us/sample - loss: 623.7128\n",
      "Epoch 177/300\n",
      "25/25 [==============================] - 0s 173us/sample - loss: 620.7066\n",
      "Epoch 178/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 617.6907\n",
      "Epoch 179/300\n",
      "25/25 [==============================] - 0s 156us/sample - loss: 614.6653\n",
      "Epoch 180/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 611.6309\n",
      "Epoch 181/300\n",
      "25/25 [==============================] - 0s 172us/sample - loss: 608.5875\n",
      "Epoch 182/300\n",
      "25/25 [==============================] - 0s 230us/sample - loss: 605.5355\n",
      "Epoch 183/300\n",
      "25/25 [==============================] - 0s 238us/sample - loss: 602.4752\n",
      "Epoch 184/300\n",
      "25/25 [==============================] - 0s 217us/sample - loss: 599.4069\n",
      "Epoch 185/300\n",
      "25/25 [==============================] - 0s 170us/sample - loss: 596.3307\n",
      "Epoch 186/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 593.2471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/300\n",
      "25/25 [==============================] - 0s 178us/sample - loss: 590.1563\n",
      "Epoch 188/300\n",
      "25/25 [==============================] - 0s 161us/sample - loss: 587.0586\n",
      "Epoch 189/300\n",
      "25/25 [==============================] - 0s 185us/sample - loss: 583.9542\n",
      "Epoch 190/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 580.8435\n",
      "Epoch 191/300\n",
      "25/25 [==============================] - 0s 219us/sample - loss: 577.7267\n",
      "Epoch 192/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 574.6041\n",
      "Epoch 193/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 571.4761\n",
      "Epoch 194/300\n",
      "25/25 [==============================] - 0s 145us/sample - loss: 568.3429\n",
      "Epoch 195/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 565.2048\n",
      "Epoch 196/300\n",
      "25/25 [==============================] - 0s 163us/sample - loss: 562.0619\n",
      "Epoch 197/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 558.9148\n",
      "Epoch 198/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 555.7636\n",
      "Epoch 199/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 552.6086\n",
      "Epoch 200/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 549.4501\n",
      "Epoch 201/300\n",
      "25/25 [==============================] - 0s 209us/sample - loss: 546.2885\n",
      "Epoch 202/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 543.1240\n",
      "Epoch 203/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 539.9568\n",
      "Epoch 204/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 536.7872\n",
      "Epoch 205/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 533.6156\n",
      "Epoch 206/300\n",
      "25/25 [==============================] - 0s 136us/sample - loss: 530.4423\n",
      "Epoch 207/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 527.2675\n",
      "Epoch 208/300\n",
      "25/25 [==============================] - 0s 144us/sample - loss: 524.0914\n",
      "Epoch 209/300\n",
      "25/25 [==============================] - 0s 197us/sample - loss: 520.9144\n",
      "Epoch 210/300\n",
      "25/25 [==============================] - 0s 222us/sample - loss: 517.7369\n",
      "Epoch 211/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 514.5589\n",
      "Epoch 212/300\n",
      "25/25 [==============================] - 0s 146us/sample - loss: 511.3809\n",
      "Epoch 213/300\n",
      "25/25 [==============================] - 0s 155us/sample - loss: 508.2030\n",
      "Epoch 214/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 505.0257\n",
      "Epoch 215/300\n",
      "25/25 [==============================] - 0s 170us/sample - loss: 501.8491\n",
      "Epoch 216/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 498.6736\n",
      "Epoch 217/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 495.4993\n",
      "Epoch 218/300\n",
      "25/25 [==============================] - 0s 150us/sample - loss: 492.3266\n",
      "Epoch 219/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 489.1558\n",
      "Epoch 220/300\n",
      "25/25 [==============================] - 0s 240us/sample - loss: 485.9871\n",
      "Epoch 221/300\n",
      "25/25 [==============================] - 0s 152us/sample - loss: 482.8208\n",
      "Epoch 222/300\n",
      "25/25 [==============================] - 0s 135us/sample - loss: 479.6571\n",
      "Epoch 223/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 476.4964\n",
      "Epoch 224/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 473.3389\n",
      "Epoch 225/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 470.1848\n",
      "Epoch 226/300\n",
      "25/25 [==============================] - 0s 145us/sample - loss: 467.0343\n",
      "Epoch 227/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 463.8879\n",
      "Epoch 228/300\n",
      "25/25 [==============================] - 0s 205us/sample - loss: 460.7457\n",
      "Epoch 229/300\n",
      "25/25 [==============================] - 0s 219us/sample - loss: 457.6080\n",
      "Epoch 230/300\n",
      "25/25 [==============================] - 0s 168us/sample - loss: 454.4751\n",
      "Epoch 231/300\n",
      "25/25 [==============================] - 0s 195us/sample - loss: 451.3471\n",
      "Epoch 232/300\n",
      "25/25 [==============================] - 0s 142us/sample - loss: 448.2243\n",
      "Epoch 233/300\n",
      "25/25 [==============================] - 0s 141us/sample - loss: 445.1071\n",
      "Epoch 234/300\n",
      "25/25 [==============================] - 0s 142us/sample - loss: 441.9955\n",
      "Epoch 235/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 438.8900\n",
      "Epoch 236/300\n",
      "25/25 [==============================] - 0s 220us/sample - loss: 435.7906\n",
      "Epoch 237/300\n",
      "25/25 [==============================] - 0s 258us/sample - loss: 432.6977\n",
      "Epoch 238/300\n",
      "25/25 [==============================] - 0s 204us/sample - loss: 429.6116\n",
      "Epoch 239/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 426.5323\n",
      "Epoch 240/300\n",
      "25/25 [==============================] - 0s 137us/sample - loss: 423.4602\n",
      "Epoch 241/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 420.3955\n",
      "Epoch 242/300\n",
      "25/25 [==============================] - 0s 161us/sample - loss: 417.3384\n",
      "Epoch 243/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 414.2892\n",
      "Epoch 244/300\n",
      "25/25 [==============================] - 0s 123us/sample - loss: 411.2480\n",
      "Epoch 245/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 408.2151\n",
      "Epoch 246/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 405.1908\n",
      "Epoch 247/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 402.1752\n",
      "Epoch 248/300\n",
      "25/25 [==============================] - 0s 165us/sample - loss: 399.1685\n",
      "Epoch 249/300\n",
      "25/25 [==============================] - 0s 183us/sample - loss: 396.1709\n",
      "Epoch 250/300\n",
      "25/25 [==============================] - 0s 149us/sample - loss: 393.1828\n",
      "Epoch 251/300\n",
      "25/25 [==============================] - 0s 145us/sample - loss: 390.2042\n",
      "Epoch 252/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 387.2354\n",
      "Epoch 253/300\n",
      "25/25 [==============================] - 0s 145us/sample - loss: 384.2765\n",
      "Epoch 254/300\n",
      "25/25 [==============================] - 0s 157us/sample - loss: 381.3278\n",
      "Epoch 255/300\n",
      "25/25 [==============================] - 0s 176us/sample - loss: 378.3895\n",
      "Epoch 256/300\n",
      "25/25 [==============================] - 0s 199us/sample - loss: 375.4616\n",
      "Epoch 257/300\n",
      "25/25 [==============================] - 0s 164us/sample - loss: 372.5446\n",
      "Epoch 258/300\n",
      "25/25 [==============================] - 0s 153us/sample - loss: 369.6386\n",
      "Epoch 259/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 366.7436\n",
      "Epoch 260/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 363.8599\n",
      "Epoch 261/300\n",
      "25/25 [==============================] - 0s 202us/sample - loss: 360.9877\n",
      "Epoch 262/300\n",
      "25/25 [==============================] - 0s 208us/sample - loss: 358.1272\n",
      "Epoch 263/300\n",
      "25/25 [==============================] - 0s 154us/sample - loss: 355.2785\n",
      "Epoch 264/300\n",
      "25/25 [==============================] - 0s 197us/sample - loss: 352.4418\n",
      "Epoch 265/300\n",
      "25/25 [==============================] - 0s 205us/sample - loss: 349.6173\n",
      "Epoch 266/300\n",
      "25/25 [==============================] - 0s 151us/sample - loss: 346.8052\n",
      "Epoch 267/300\n",
      "25/25 [==============================] - 0s 140us/sample - loss: 344.0055\n",
      "Epoch 268/300\n",
      "25/25 [==============================] - 0s 167us/sample - loss: 341.2185\n",
      "Epoch 269/300\n",
      "25/25 [==============================] - 0s 127us/sample - loss: 338.4443\n",
      "Epoch 270/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 335.6831\n",
      "Epoch 271/300\n",
      "25/25 [==============================] - 0s 148us/sample - loss: 332.9350\n",
      "Epoch 272/300\n",
      "25/25 [==============================] - 0s 161us/sample - loss: 330.2002\n",
      "Epoch 273/300\n",
      "25/25 [==============================] - 0s 213us/sample - loss: 327.4788\n",
      "Epoch 274/300\n",
      "25/25 [==============================] - 0s 232us/sample - loss: 324.7709\n",
      "Epoch 275/300\n",
      "25/25 [==============================] - 0s 162us/sample - loss: 322.0768\n",
      "Epoch 276/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 319.3964\n",
      "Epoch 277/300\n",
      "25/25 [==============================] - 0s 134us/sample - loss: 316.7301\n",
      "Epoch 278/300\n",
      "25/25 [==============================] - 0s 181us/sample - loss: 314.0778\n",
      "Epoch 279/300\n",
      "25/25 [==============================] - 0s 147us/sample - loss: 311.4398\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 137us/sample - loss: 308.8161\n",
      "Epoch 281/300\n",
      "25/25 [==============================] - 0s 171us/sample - loss: 306.2069\n",
      "Epoch 282/300\n",
      "25/25 [==============================] - 0s 193us/sample - loss: 303.6123\n",
      "Epoch 283/300\n",
      "25/25 [==============================] - 0s 177us/sample - loss: 301.0324\n",
      "Epoch 284/300\n",
      "25/25 [==============================] - 0s 156us/sample - loss: 298.4673\n",
      "Epoch 285/300\n",
      "25/25 [==============================] - 0s 170us/sample - loss: 295.9171\n",
      "Epoch 286/300\n",
      "25/25 [==============================] - 0s 156us/sample - loss: 293.3820\n",
      "Epoch 287/300\n",
      "25/25 [==============================] - 0s 166us/sample - loss: 290.8620\n",
      "Epoch 288/300\n",
      "25/25 [==============================] - 0s 143us/sample - loss: 288.3573\n",
      "Epoch 289/300\n",
      "25/25 [==============================] - 0s 171us/sample - loss: 285.8679\n",
      "Epoch 290/300\n",
      "25/25 [==============================] - 0s 181us/sample - loss: 283.3939\n",
      "Epoch 291/300\n",
      "25/25 [==============================] - 0s 224us/sample - loss: 280.9355\n",
      "Epoch 292/300\n",
      "25/25 [==============================] - 0s 221us/sample - loss: 278.4926\n",
      "Epoch 293/300\n",
      "25/25 [==============================] - 0s 131us/sample - loss: 276.0656\n",
      "Epoch 294/300\n",
      "25/25 [==============================] - 0s 184us/sample - loss: 273.6542\n",
      "Epoch 295/300\n",
      "25/25 [==============================] - 0s 179us/sample - loss: 271.2588\n",
      "Epoch 296/300\n",
      "25/25 [==============================] - 0s 169us/sample - loss: 268.8793\n",
      "Epoch 297/300\n",
      "25/25 [==============================] - 0s 146us/sample - loss: 266.5158\n",
      "Epoch 298/300\n",
      "25/25 [==============================] - 0s 159us/sample - loss: 264.1684\n",
      "Epoch 299/300\n",
      "25/25 [==============================] - 0s 238us/sample - loss: 261.8372\n",
      "Epoch 300/300\n",
      "25/25 [==============================] - 0s 192us/sample - loss: 259.5221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1309855f8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=300,batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(len(loss)),y=loss)\n",
    "plt.title(\"Training Loss per Epoch\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.223388671875"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score = model.evaluate(X_train,y_train,verbose=0)\n",
    "training_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [11,100] vs. [25,100]\n\t [[{{node lstm/while/add_7}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-103177d3245f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [11,100] vs. [25,100]\n\t [[{{node lstm/while/add_7}}]]"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.198507 ],\n",
       "       [ 6.8823433],\n",
       "       [ 9.764395 ],\n",
       "       [18.611313 ],\n",
       "       [13.081752 ],\n",
       "       [16.087698 ],\n",
       "       [10.504973 ],\n",
       "       [14.996562 ],\n",
       "       [ 7.5871906],\n",
       "       [14.88369  ],\n",
       "       [ 8.303727 ],\n",
       "       [21.494188 ],\n",
       "       [ 9.030068 ],\n",
       "       [20.783161 ],\n",
       "       [19.03406  ],\n",
       "       [17.133955 ],\n",
       "       [14.248598 ],\n",
       "       [18.305264 ],\n",
       "       [15.339937 ],\n",
       "       [15.6374235],\n",
       "       [11.2501745],\n",
       "       [16.831593 ],\n",
       "       [11.998471 ],\n",
       "       [12.327466 ],\n",
       "       [17.875319 ]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(y_test,columns=['Test Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
